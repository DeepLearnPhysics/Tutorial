{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train a simple, 10-layers deep convolutional neural network for classifying 5 particle images in a simulated LArTPC detecotr available from the [public dataset](http://deeplearnphysics.org/DataChallenge). We use tensorflow to train the network and `larcv_threadio` to fetch data from larcv files. First, let's prepare data samples. For the setup of this example, I need to prepare `practice_train_10k.root` and `practice_test_10k.root` in the current directory. Let us make symbolic links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Preparation: make symbolic links for practice_train_10k.root and practice_test_10k.root\n",
    "PRACTICE_FILE_DIR=../../\n",
    "ln -sf $PRACTICE_FILE_DIR/practice_train_5k.root ./train.root\n",
    "ln -sf $PRACTICE_FILE_DIR/practice_test_5k.root ./test.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from larcv import larcv\n",
    "from larcv.dataloader2 import larcv_threadio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os,sys,time\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set `os.environ['TF_CPP_MIN_LOG_LEVEL']` to suppress lots of *non-error* (standard) output from tensorflow because it can overwhelm ipython's capability to fetch `stdout` stream.\n",
    "\n",
    "## Configurations\n",
    "Next, let's define configuration variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TUTORIAL_DIR     = '..'\n",
    "TRAIN_IO_CONFIG  = os.path.join(TUTORIAL_DIR, 'tf/io_train.cfg')\n",
    "TEST_IO_CONFIG   = os.path.join(TUTORIAL_DIR, 'tf/io_test.cfg' )\n",
    "TRAIN_BATCH_SIZE = 50\n",
    "TEST_BATCH_SIZE  = 100\n",
    "LOGDIR           = 'log'\n",
    "ITERATIONS       = 4000\n",
    "SAVE_SUMMARY     = 20\n",
    "SAVE_WEIGHTS     = 100\n",
    "\n",
    "# Check log directory is empty\n",
    "train_logdir = os.path.join(LOGDIR,'train')\n",
    "test_logdir  = os.path.join(LOGDIR,'test')\n",
    "if not os.path.isdir(train_logdir): os.makedirs(train_logdir)\n",
    "if not os.path.isdir(test_logdir):  os.makedirs(test_logdir)\n",
    "if len(os.listdir(train_logdir)) or len(os.listdir(test_logdir)):\n",
    "  sys.stderr.write('Error: train or test log dir not empty...\\n')\n",
    "  raise OSError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot\n",
    "\n",
    "## Configure data reader\n",
    "We prepare two data reader instances: one for training and another for testing the network. Testing is not absolutely needed but we try here to just cover in this example. We don't go in details of how `larcv_threadio` works here since there is [a dedicated tutorial](http://deeplearnphysics.org/Blog/tutorial-04.html) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m setting verbosity \u001b[00m3\r\n",
      "\u001b[93m setting verbosity \u001b[00m3\r\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 0: IO\n",
    "#\n",
    "# for \"train\" data set\n",
    "train_io = larcv_threadio()  # create io interface\n",
    "train_io_cfg = {'filler_name' : 'TrainIO',\n",
    "                'verbosity'   : 0,\n",
    "                'filler_cfg'  : TRAIN_IO_CONFIG}\n",
    "train_io.configure(train_io_cfg)   # configure\n",
    "train_io.start_manager(TRAIN_BATCH_SIZE) # start read thread\n",
    "time.sleep(2)\n",
    "train_io.next()\n",
    "\n",
    "# for \"test\" data set\n",
    "test_io = larcv_threadio()   # create io interface\n",
    "test_io_cfg = {'filler_name' : 'TestIO',\n",
    "               'verbosity'   : 0,\n",
    "               'filler_cfg'  : TEST_IO_CONFIG}\n",
    "test_io.configure(test_io_cfg)   # configure\n",
    "test_io.start_manager(TEST_BATCH_SIZE) # start read thread\n",
    "time.sleep(2)\n",
    "test_io.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a network\n",
    "Let's construct a simple network for this exercise. We use 5x2 convolution layers with max-pooling operation followed after every 2 convolution layers except the last layer is average-pooling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Step 1: Define network\n",
    "#\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.python.platform\n",
    "\n",
    "def build(input_tensor, num_class=4, trainable=True, debug=True):\n",
    "\n",
    "    net = input_tensor\n",
    "    if debug: print 'input tensor:', input_tensor.shape\n",
    "\n",
    "    filters = 32\n",
    "    num_modules = 5\n",
    "    with tf.variable_scope('conv'):\n",
    "        for step in xrange(5):\n",
    "            stride = 2\n",
    "            if step: stride = 1\n",
    "            net = slim.conv2d(inputs        = net,        # input tensor\n",
    "                              num_outputs   = filters,    # number of filters (neurons) = # of output feature maps\n",
    "                              kernel_size   = [3,3],      # kernel size\n",
    "                              stride        = stride,     # stride size\n",
    "                              trainable     = trainable,  # train or inference\n",
    "                              activation_fn = tf.nn.relu, # relu\n",
    "                              scope         = 'conv%da_conv' % step)\n",
    "\n",
    "            net = slim.conv2d(inputs        = net,        # input tensor\n",
    "                              num_outputs   = filters,    # number of filters (neurons) = # of output feature maps\n",
    "                              kernel_size   = [3,3],      # kernel size\n",
    "                              stride        = 1,          # stride size\n",
    "                              trainable     = trainable,  # train or inference\n",
    "                              activation_fn = tf.nn.relu, # relu\n",
    "                              scope         = 'conv%db_conv' % step)\n",
    "            if (step+1) < num_modules:\n",
    "                net = slim.max_pool2d(inputs      = net,    # input tensor\n",
    "                                      kernel_size = [2,2],  # kernel size\n",
    "                                      stride      = 2,      # stride size\n",
    "                                      scope       = 'conv%d_pool' % step)\n",
    "\n",
    "            else:\n",
    "                net = tf.layers.average_pooling2d(inputs = net,\n",
    "                                                  pool_size = [net.get_shape()[-2].value,net.get_shape()[-3].value],\n",
    "                                                  strides = 1,\n",
    "                                                  padding = 'valid',\n",
    "                                                  name = 'conv%d_pool' % step)\n",
    "            filters *= 2\n",
    "\n",
    "            if debug: print 'After step',step,'shape',net.shape\n",
    "\n",
    "    with tf.variable_scope('final'):\n",
    "        net = slim.flatten(net, scope='flatten')\n",
    "\n",
    "        if debug: print 'After flattening', net.shape\n",
    "\n",
    "        net = slim.fully_connected(net, int(num_class), scope='final_fc')\n",
    "\n",
    "        if debug: print 'After final_fc', net.shape\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "Build the network and define loss, accuracy metrics and our solver. Any optimizer should work but you may have to tune the parameters by yourself. Here, we use `RMSPropOptimizer` with base learning rate `0.0005` with no justification. Note we add minimal set of tensorflow variables into tf.summary to demonstrate later the `tensorboard`, a dedicated monitoring/visualization tool for network training with tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Step 2: Build network + define loss & solver\n",
    "#\n",
    "# retrieve dimensions of data for network construction\n",
    "dim_data  = train_io.fetch_data('train_image').dim()\n",
    "dim_label = train_io.fetch_data('train_label').dim()\n",
    "# define place holders\n",
    "data_tensor    = tf.placeholder(tf.float32, [None, dim_data[1] * dim_data[2] * dim_data[3]], name='image')\n",
    "label_tensor   = tf.placeholder(tf.float32, [None, dim_label[1]], name='label')\n",
    "data_tensor_2d = tf.reshape(data_tensor, [-1,dim_data[1],dim_data[2],dim_data[3]],name='image_reshape')\n",
    "\n",
    "# Let's keep 10 random set of images in the log\n",
    "tf.summary.image('input',data_tensor_2d,10)\n",
    "# build net\n",
    "net = build(input_tensor=data_tensor_2d, num_class=dim_label[1], trainable=True, debug=False)\n",
    "# Define accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(net,1), tf.argmax(label_tensor,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "# Define loss + backprop as training step\n",
    "with tf.name_scope('train'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label_tensor, logits=net))\n",
    "    tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "    train_step = tf.train.RMSPropOptimizer(0.00005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining tensorflow IO\n",
    "In the next cell we define tensorflow's IO\n",
    "* `merged_summary` is tensorflow operation to create summaries to be written into a _log file_ for `tensorboard`.\n",
    "* `writer_train` writes monitoring data for training data sample into a log file.\n",
    "* `writer_test` is same as `writer_train` except it is for testing data sample.\n",
    "* `saver` is a handle to store the state of the network = trained network variable values (weights, biases, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                                                                                                                                      \n",
    "# Step 3: weight saver & summary writer                                                                                                \n",
    "#                                                                                                                                      \n",
    "# Create a bandle of summary                                                                                                           \n",
    "merged_summary=tf.summary.merge_all()\n",
    "# Create a session                                                                                                                     \n",
    "sess = tf.InteractiveSession()\n",
    "# Initialize variables                                                                                                                 \n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Create a summary writer handle                                                                                                       \n",
    "writer_train=tf.summary.FileWriter(train_logdir)\n",
    "writer_train.add_graph(sess.graph)\n",
    "writer_test=tf.summary.FileWriter(test_logdir)\n",
    "writer_test.add_graph(sess.graph)\n",
    "# Create weights saver                                                                                                                 \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress @ step 19 loss 1.61877 accuracy 0.16          \n",
      "Testing in progress @ step 19 loss 1.60783 accuracy 0.23          \n",
      "Training in progress @ step 39 loss 1.61364 accuracy 0.18          \n",
      "Testing in progress @ step 39 loss 1.61729 accuracy 0.16          \n",
      "Training in progress @ step 59 loss 1.60067 accuracy 0.2          \n",
      "Testing in progress @ step 59 loss 1.60024 accuracy 0.31          \n",
      "Training in progress @ step 79 loss 1.60721 accuracy 0.2          \n",
      "Testing in progress @ step 79 loss 1.6006 accuracy 0.2          \n",
      "Training in progress @ step 99 loss 1.58752 accuracy 0.24          \n",
      "Testing in progress @ step 99 loss 1.58583 accuracy 0.24          \n",
      "saved @ weights/toynet-99\n",
      "Training in progress @ step 119 loss 1.56747 accuracy 0.2          \n",
      "Testing in progress @ step 119 loss 1.55061 accuracy 0.23          \n",
      "Training in progress @ step 139 loss 1.57683 accuracy 0.26          \n",
      "Testing in progress @ step 139 loss 1.58774 accuracy 0.29          \n",
      "Training in progress @ step 159 loss 1.54762 accuracy 0.22          \n",
      "Testing in progress @ step 159 loss 1.50536 accuracy 0.34          \n",
      "Training in progress @ step 179 loss 1.58266 accuracy 0.28          \n",
      "Testing in progress @ step 179 loss 1.44747 accuracy 0.41          \n",
      "Training in progress @ step 199 loss 1.5332 accuracy 0.36          \n",
      "Testing in progress @ step 199 loss 1.57948 accuracy 0.29          \n",
      "saved @ weights/toynet-199\n",
      "Training in progress @ step 219 loss 1.48542 accuracy 0.3          \n",
      "Testing in progress @ step 219 loss 1.58982 accuracy 0.25          \n",
      "Training in progress @ step 239 loss 1.36492 accuracy 0.28          \n",
      "Testing in progress @ step 239 loss 1.35861 accuracy 0.37          \n",
      "Training in progress @ step 259 loss 1.29231 accuracy 0.48          \n",
      "Testing in progress @ step 259 loss 1.32551 accuracy 0.4          \n",
      "Training in progress @ step 279 loss 1.38555 accuracy 0.28          \n",
      "Testing in progress @ step 279 loss 1.22087 accuracy 0.48          \n",
      "Training in progress @ step 299 loss 1.21932 accuracy 0.52          \n",
      "Testing in progress @ step 299 loss 1.30527 accuracy 0.44          \n",
      "saved @ weights/toynet-299\n",
      "Training in progress @ step 319 loss 1.27938 accuracy 0.38          \n",
      "Testing in progress @ step 319 loss 1.37962 accuracy 0.35          \n",
      "Training in progress @ step 339 loss 1.29448 accuracy 0.52          \n",
      "Testing in progress @ step 339 loss 1.20251 accuracy 0.47          \n",
      "Training in progress @ step 359 loss 1.126 accuracy 0.46          \n",
      "Testing in progress @ step 359 loss 1.10763 accuracy 0.48          \n",
      "Training in progress @ step 379 loss 1.17514 accuracy 0.38          \n",
      "Testing in progress @ step 379 loss 1.04698 accuracy 0.58          \n",
      "Training in progress @ step 399 loss 1.07519 accuracy 0.6          \n",
      "Testing in progress @ step 399 loss 1.28119 accuracy 0.36          \n",
      "saved @ weights/toynet-399\n",
      "Training in progress @ step 419 loss 1.16095 accuracy 0.46          \n",
      "Testing in progress @ step 419 loss 1.07793 accuracy 0.52          \n",
      "Training in progress @ step 439 loss 1.1039 accuracy 0.4          \n",
      "Testing in progress @ step 439 loss 1.04698 accuracy 0.63          \n",
      "Training in progress @ step 459 loss 1.04501 accuracy 0.62          \n",
      "Testing in progress @ step 459 loss 1.19266 accuracy 0.46          \n",
      "Training in progress @ step 479 loss 1.12457 accuracy 0.46          \n",
      "Testing in progress @ step 479 loss 1.06707 accuracy 0.48          \n",
      "Training in progress @ step 499 loss 1.24122 accuracy 0.46          \n",
      "Testing in progress @ step 499 loss 1.1237 accuracy 0.48          \n",
      "saved @ weights/toynet-499\n",
      "Training in progress @ step 519 loss 1.0712 accuracy 0.44          \n",
      "Testing in progress @ step 519 loss 0.957331 accuracy 0.55          \n",
      "Training in progress @ step 539 loss 1.17704 accuracy 0.52          \n",
      "Testing in progress @ step 539 loss 1.04453 accuracy 0.56          \n",
      "Training in progress @ step 559 loss 0.952621 accuracy 0.62          \n",
      "Testing in progress @ step 559 loss 1.01518 accuracy 0.54          \n",
      "Training in progress @ step 579 loss 1.02542 accuracy 0.5          \n",
      "Testing in progress @ step 579 loss 1.02783 accuracy 0.52          \n",
      "Training in progress @ step 599 loss 1.24 accuracy 0.38          \n",
      "Testing in progress @ step 599 loss 1.11483 accuracy 0.46          \n",
      "saved @ weights/toynet-599\n",
      "Training in progress @ step 619 loss 0.945926 accuracy 0.68          \n",
      "Testing in progress @ step 619 loss 1.15469 accuracy 0.43          \n",
      "Training in progress @ step 639 loss 1.14942 accuracy 0.56          \n",
      "Testing in progress @ step 639 loss 1.02352 accuracy 0.46          \n",
      "Training in progress @ step 659 loss 0.905438 accuracy 0.62          \n",
      "Testing in progress @ step 659 loss 0.953731 accuracy 0.52          \n",
      "Training in progress @ step 679 loss 0.937925 accuracy 0.5          \n",
      "Testing in progress @ step 679 loss 0.974151 accuracy 0.56          \n",
      "Training in progress @ step 699 loss 1.16791 accuracy 0.44          \n",
      "Testing in progress @ step 699 loss 0.792396 accuracy 0.65          \n",
      "saved @ weights/toynet-699\n",
      "Training in progress @ step 719 loss 0.98803 accuracy 0.5          \n",
      "Testing in progress @ step 719 loss 0.942351 accuracy 0.57          \n",
      "Training in progress @ step 739 loss 0.956151 accuracy 0.48          \n",
      "Testing in progress @ step 739 loss 0.959132 accuracy 0.59          \n",
      "Training in progress @ step 759 loss 0.929964 accuracy 0.56          \n",
      "Testing in progress @ step 759 loss 1.03519 accuracy 0.6          \n",
      "Training in progress @ step 779 loss 0.942782 accuracy 0.52          \n",
      "Testing in progress @ step 779 loss 0.987597 accuracy 0.56          \n",
      "Training in progress @ step 799 loss 1.12933 accuracy 0.44          \n",
      "Testing in progress @ step 799 loss 0.888236 accuracy 0.6          \n",
      "saved @ weights/toynet-799\n",
      "Training in progress @ step 819 loss 1.02685 accuracy 0.48          \n",
      "Testing in progress @ step 819 loss 0.957893 accuracy 0.62          \n",
      "Training in progress @ step 839 loss 1.14004 accuracy 0.56          \n",
      "Testing in progress @ step 839 loss 0.908557 accuracy 0.53          \n",
      "Training in progress @ step 859 loss 0.950782 accuracy 0.62          \n",
      "Testing in progress @ step 859 loss 0.878652 accuracy 0.65          \n",
      "Training in progress @ step 879 loss 0.806053 accuracy 0.56          \n",
      "Testing in progress @ step 879 loss 0.989885 accuracy 0.47          \n",
      "Training in progress @ step 899 loss 1.25186 accuracy 0.44          \n",
      "Testing in progress @ step 899 loss 1.05391 accuracy 0.52          \n",
      "saved @ weights/toynet-899\n",
      "Training in progress @ step 919 loss 0.969915 accuracy 0.52          \n",
      "Testing in progress @ step 919 loss 0.93315 accuracy 0.6          \n",
      "Training in progress @ step 939 loss 1.0859 accuracy 0.58          \n",
      "Testing in progress @ step 939 loss 0.887738 accuracy 0.61          \n",
      "Training in progress @ step 959 loss 0.866381 accuracy 0.62          \n",
      "Testing in progress @ step 959 loss 0.963727 accuracy 0.55          \n",
      "Training in progress @ step 979 loss 0.749437 accuracy 0.66          \n",
      "Testing in progress @ step 979 loss 0.772379 accuracy 0.61          \n",
      "Training in progress @ step 999 loss 1.10315 accuracy 0.58          \n",
      "Testing in progress @ step 999 loss 1.02588 accuracy 0.62          \n",
      "saved @ weights/toynet-999\n",
      "Training in progress @ step 1019 loss 0.998402 accuracy 0.54          \n",
      "Testing in progress @ step 1019 loss 0.926266 accuracy 0.52          \n",
      "Training in progress @ step 1039 loss 0.898997 accuracy 0.5          \n",
      "Testing in progress @ step 1039 loss 0.782953 accuracy 0.65          \n",
      "Training in progress @ step 1059 loss 0.846287 accuracy 0.64          \n",
      "Testing in progress @ step 1059 loss 0.88855 accuracy 0.57          \n",
      "Training in progress @ step 1079 loss 0.844313 accuracy 0.56          \n",
      "Testing in progress @ step 1079 loss 0.813727 accuracy 0.65          \n",
      "Training in progress @ step 1099 loss 0.845931 accuracy 0.64          \n",
      "Testing in progress @ step 1099 loss 1.21106 accuracy 0.54          \n",
      "saved @ weights/toynet-1099\n",
      "Training in progress @ step 1119 loss 1.03955 accuracy 0.5          \n",
      "Testing in progress @ step 1119 loss 1.00184 accuracy 0.51          \n",
      "Training in progress @ step 1139 loss 1.03947 accuracy 0.58          \n",
      "Testing in progress @ step 1139 loss 0.758581 accuracy 0.68          \n",
      "Training in progress @ step 1159 loss 0.797802 accuracy 0.66          \n",
      "Testing in progress @ step 1159 loss 0.851378 accuracy 0.6          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress @ step 1179 loss 0.894696 accuracy 0.56          \n",
      "Testing in progress @ step 1179 loss 0.850195 accuracy 0.59          \n",
      "Training in progress @ step 1199 loss 0.970576 accuracy 0.5          \n",
      "Testing in progress @ step 1199 loss 0.840837 accuracy 0.6          \n",
      "saved @ weights/toynet-1199\n",
      "Training in progress @ step 1219 loss 1.07365 accuracy 0.46          \n",
      "Testing in progress @ step 1219 loss 1.0057 accuracy 0.58          \n",
      "Training in progress @ step 1239 loss 1.05924 accuracy 0.62          \n",
      "Testing in progress @ step 1239 loss 0.768942 accuracy 0.68          \n",
      "Training in progress @ step 1259 loss 0.781172 accuracy 0.68          \n",
      "Testing in progress @ step 1259 loss 0.875281 accuracy 0.57          \n",
      "Training in progress @ step 1279 loss 0.727266 accuracy 0.68          \n",
      "Testing in progress @ step 1279 loss 0.840267 accuracy 0.63          \n",
      "Training in progress @ step 1299 loss 0.924895 accuracy 0.48          \n",
      "Testing in progress @ step 1299 loss 0.898691 accuracy 0.61          \n",
      "saved @ weights/toynet-1299\n",
      "Training in progress @ step 1319 loss 0.921912 accuracy 0.52          \n",
      "Testing in progress @ step 1319 loss 0.823253 accuracy 0.66          \n",
      "Training in progress @ step 1339 loss 0.820703 accuracy 0.6          \n",
      "Testing in progress @ step 1339 loss 0.752571 accuracy 0.67          \n",
      "Training in progress @ step 1359 loss 0.773544 accuracy 0.68          \n",
      "Testing in progress @ step 1359 loss 0.940625 accuracy 0.47          \n",
      "Training in progress @ step 1379 loss 0.923685 accuracy 0.58          \n",
      "Testing in progress @ step 1379 loss 0.770226 accuracy 0.66          \n",
      "Training in progress @ step 1399 loss 0.891731 accuracy 0.56          \n",
      "Testing in progress @ step 1399 loss 0.816133 accuracy 0.63          \n",
      "saved @ weights/toynet-1399\n",
      "Training in progress @ step 1419 loss 1.01212 accuracy 0.48          \n",
      "Testing in progress @ step 1419 loss 0.885064 accuracy 0.57          \n",
      "Training in progress @ step 1439 loss 0.888119 accuracy 0.5          \n",
      "Testing in progress @ step 1439 loss 0.74117 accuracy 0.71          \n",
      "Training in progress @ step 1459 loss 0.799632 accuracy 0.68          \n",
      "Testing in progress @ step 1459 loss 0.878776 accuracy 0.51          \n",
      "Training in progress @ step 1479 loss 0.673832 accuracy 0.68          \n",
      "Testing in progress @ step 1479 loss 0.829453 accuracy 0.62          \n",
      "Training in progress @ step 1499 loss 0.920442 accuracy 0.54          \n",
      "Testing in progress @ step 1499 loss 0.954242 accuracy 0.55          \n",
      "saved @ weights/toynet-1499\n",
      "Training in progress @ step 1519 loss 0.92775 accuracy 0.5          \n",
      "Testing in progress @ step 1519 loss 1.05776 accuracy 0.56          \n",
      "Training in progress @ step 1539 loss 0.89591 accuracy 0.58          \n",
      "Testing in progress @ step 1539 loss 0.870094 accuracy 0.56          \n",
      "Training in progress @ step 1559 loss 0.773939 accuracy 0.66          \n",
      "Testing in progress @ step 1559 loss 0.801418 accuracy 0.6          \n",
      "Training in progress @ step 1579 loss 0.750542 accuracy 0.62          \n",
      "Testing in progress @ step 1579 loss 0.924279 accuracy 0.56          \n",
      "Training in progress @ step 1599 loss 0.825358 accuracy 0.66          \n",
      "Testing in progress @ step 1599 loss 0.828892 accuracy 0.6          \n",
      "saved @ weights/toynet-1599\n",
      "Training in progress @ step 1619 loss 0.927536 accuracy 0.56          \n",
      "Testing in progress @ step 1619 loss 1.0899 accuracy 0.63          \n",
      "Training in progress @ step 1639 loss 0.757635 accuracy 0.62          \n",
      "Testing in progress @ step 1639 loss 0.834759 accuracy 0.58          \n",
      "Training in progress @ step 1659 loss 0.766745 accuracy 0.68          \n",
      "Testing in progress @ step 1659 loss 0.798205 accuracy 0.59          \n",
      "Training in progress @ step 1679 loss 0.685779 accuracy 0.64          \n",
      "Testing in progress @ step 1679 loss 0.884735 accuracy 0.59          \n",
      "Training in progress @ step 1699 loss 0.940616 accuracy 0.54          \n",
      "Testing in progress @ step 1699 loss 0.696472 accuracy 0.69          \n",
      "saved @ weights/toynet-1699\n",
      "Training in progress @ step 1719 loss 0.865781 accuracy 0.54          \n",
      "Testing in progress @ step 1719 loss 0.8877 accuracy 0.63          \n",
      "Training in progress @ step 1739 loss 0.954459 accuracy 0.62          \n",
      "Testing in progress @ step 1739 loss 0.801446 accuracy 0.66          \n",
      "Training in progress @ step 1759 loss 0.686381 accuracy 0.74          \n",
      "Testing in progress @ step 1759 loss 0.935733 accuracy 0.62          \n",
      "Training in progress @ step 1779 loss 0.74856 accuracy 0.66          \n",
      "Testing in progress @ step 1779 loss 1.05489 accuracy 0.58          \n",
      "Training in progress @ step 1799 loss 0.81451 accuracy 0.58          \n",
      "Testing in progress @ step 1799 loss 0.705272 accuracy 0.72          \n",
      "saved @ weights/toynet-1799\n",
      "Training in progress @ step 1819 loss 0.934223 accuracy 0.54          \n",
      "Testing in progress @ step 1819 loss 0.912457 accuracy 0.66          \n",
      "Training in progress @ step 1839 loss 0.928289 accuracy 0.7          \n",
      "Testing in progress @ step 1839 loss 0.853922 accuracy 0.58          \n",
      "Training in progress @ step 1859 loss 0.781158 accuracy 0.7          \n",
      "Testing in progress @ step 1859 loss 0.786478 accuracy 0.69          \n",
      "Training in progress @ step 1879 loss 0.722183 accuracy 0.6          \n",
      "Testing in progress @ step 1879 loss 0.923672 accuracy 0.54          \n",
      "Training in progress @ step 1899 loss 0.757819 accuracy 0.7          \n",
      "Testing in progress @ step 1899 loss 0.876702 accuracy 0.55          \n",
      "saved @ weights/toynet-1899\n",
      "Training in progress @ step 1919 loss 0.839298 accuracy 0.64          \n",
      "Testing in progress @ step 1919 loss 0.758776 accuracy 0.69          \n",
      "Training in progress @ step 1939 loss 0.786431 accuracy 0.6          \n",
      "Testing in progress @ step 1939 loss 0.812018 accuracy 0.64          \n",
      "Training in progress @ step 1959 loss 0.714103 accuracy 0.74          \n",
      "Testing in progress @ step 1959 loss 0.837271 accuracy 0.6          \n",
      "Training in progress @ step 1979 loss 0.699254 accuracy 0.62          \n",
      "Testing in progress @ step 1979 loss 0.676771 accuracy 0.72          \n",
      "Training in progress @ step 1999 loss 0.731157 accuracy 0.74          \n",
      "Testing in progress @ step 1999 loss 0.743471 accuracy 0.69          \n",
      "saved @ weights/toynet-1999\n",
      "Training in progress @ step 2019 loss 0.995028 accuracy 0.5          \n",
      "Testing in progress @ step 2019 loss 1.10174 accuracy 0.48          \n",
      "Training in progress @ step 2039 loss 0.910528 accuracy 0.68          \n",
      "Testing in progress @ step 2039 loss 0.878861 accuracy 0.59          \n",
      "Training in progress @ step 2059 loss 0.707643 accuracy 0.74          \n",
      "Testing in progress @ step 2059 loss 0.869293 accuracy 0.6          \n",
      "Training in progress @ step 2079 loss 0.762543 accuracy 0.64          \n",
      "Testing in progress @ step 2079 loss 0.729145 accuracy 0.67          \n",
      "Training in progress @ step 2099 loss 0.839904 accuracy 0.58          \n",
      "Testing in progress @ step 2099 loss 1.04243 accuracy 0.55          \n",
      "saved @ weights/toynet-2099\n",
      "Training in progress @ step 2119 loss 0.842977 accuracy 0.58          \n",
      "Testing in progress @ step 2119 loss 1.01768 accuracy 0.59          \n",
      "Training in progress @ step 2139 loss 0.935526 accuracy 0.64          \n",
      "Testing in progress @ step 2139 loss 0.715847 accuracy 0.71          \n",
      "Training in progress @ step 2159 loss 0.731804 accuracy 0.7          \n",
      "Testing in progress @ step 2159 loss 0.760811 accuracy 0.65          \n",
      "Training in progress @ step 2179 loss 0.597135 accuracy 0.74          \n",
      "Testing in progress @ step 2179 loss 0.679645 accuracy 0.65          \n",
      "Training in progress @ step 2199 loss 0.923113 accuracy 0.56          \n",
      "Testing in progress @ step 2199 loss 1.05971 accuracy 0.56          \n",
      "saved @ weights/toynet-2199\n",
      "Training in progress @ step 2219 loss 0.933216 accuracy 0.5          \n",
      "Testing in progress @ step 2219 loss 0.930371 accuracy 0.65          \n",
      "Training in progress @ step 2239 loss 0.887308 accuracy 0.72          \n",
      "Testing in progress @ step 2239 loss 0.705166 accuracy 0.68          \n",
      "Training in progress @ step 2259 loss 0.695175 accuracy 0.74          \n",
      "Testing in progress @ step 2259 loss 0.77813 accuracy 0.63          \n",
      "Training in progress @ step 2279 loss 0.734415 accuracy 0.7          \n",
      "Testing in progress @ step 2279 loss 0.928493 accuracy 0.56          \n",
      "Training in progress @ step 2299 loss 0.776362 accuracy 0.62          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing in progress @ step 2299 loss 1.068 accuracy 0.64          \n",
      "saved @ weights/toynet-2299\n",
      "Training in progress @ step 2319 loss 1.1163 accuracy 0.44          \n",
      "Testing in progress @ step 2319 loss 0.962624 accuracy 0.61          \n",
      "Training in progress @ step 2339 loss 0.85097 accuracy 0.72          \n",
      "Testing in progress @ step 2339 loss 0.936161 accuracy 0.61          \n",
      "Training in progress @ step 2359 loss 0.674812 accuracy 0.76          \n",
      "Testing in progress @ step 2359 loss 0.907221 accuracy 0.51          \n",
      "Training in progress @ step 2379 loss 0.787386 accuracy 0.66          \n",
      "Testing in progress @ step 2379 loss 0.795084 accuracy 0.67          \n",
      "Training in progress @ step 2399 loss 1.10047 accuracy 0.5          \n",
      "Testing in progress @ step 2399 loss 1.05451 accuracy 0.51          \n",
      "saved @ weights/toynet-2399\n",
      "Training in progress @ step 2419 loss 0.9411 accuracy 0.58          \n",
      "Testing in progress @ step 2419 loss 0.726489 accuracy 0.66          \n",
      "Training in progress @ step 2439 loss 0.85241 accuracy 0.72          \n",
      "Testing in progress @ step 2439 loss 0.746389 accuracy 0.69          \n",
      "Training in progress @ step 2459 loss 0.648412 accuracy 0.78          \n",
      "Testing in progress @ step 2459 loss 0.789822 accuracy 0.58          \n",
      "Training in progress @ step 2479 loss 0.700605 accuracy 0.66          \n",
      "Testing in progress @ step 2479 loss 0.994578 accuracy 0.6          \n",
      "Training in progress @ step 2499 loss 0.888323 accuracy 0.56          \n",
      "Testing in progress @ step 2499 loss 1.20976 accuracy 0.53          \n",
      "saved @ weights/toynet-2499\n",
      "Training in progress @ step 2519 loss 0.725957 accuracy 0.64          \n",
      "Testing in progress @ step 2519 loss 0.791848 accuracy 0.63          \n",
      "Training in progress @ step 2539 loss 0.797396 accuracy 0.6          \n",
      "Testing in progress @ step 2539 loss 0.867458 accuracy 0.63          \n",
      "Training in progress @ step 2559 loss 0.659748 accuracy 0.8          \n",
      "Testing in progress @ step 2559 loss 0.767853 accuracy 0.62          \n",
      "Training in progress @ step 2579 loss 0.631964 accuracy 0.68          \n",
      "Testing in progress @ step 2579 loss 0.830835 accuracy 0.62          \n",
      "Training in progress @ step 2599 loss 0.712929 accuracy 0.64          \n",
      "Testing in progress @ step 2599 loss 0.87415 accuracy 0.66          \n",
      "saved @ weights/toynet-2599\n",
      "Training in progress @ step 2619 loss 1.00039 accuracy 0.54          \n",
      "Testing in progress @ step 2619 loss 1.18999 accuracy 0.56          \n",
      "Training in progress @ step 2639 loss 0.787397 accuracy 0.6          \n",
      "Testing in progress @ step 2639 loss 0.833899 accuracy 0.67          \n",
      "Training in progress @ step 2659 loss 0.635125 accuracy 0.8          \n",
      "Testing in progress @ step 2659 loss 0.723096 accuracy 0.63          \n",
      "Training in progress @ step 2679 loss 0.665665 accuracy 0.68          \n",
      "Testing in progress @ step 2679 loss 0.885793 accuracy 0.64          \n",
      "Training in progress @ step 2699 loss 0.713862 accuracy 0.72          \n",
      "Testing in progress @ step 2699 loss 1.01874 accuracy 0.63          \n",
      "saved @ weights/toynet-2699\n",
      "Training in progress @ step 2719 loss 0.836429 accuracy 0.6          \n",
      "Testing in progress @ step 2719 loss 0.793213 accuracy 0.65          \n",
      "Training in progress @ step 2739 loss 0.778351 accuracy 0.72          \n",
      "Testing in progress @ step 2739 loss 0.841934 accuracy 0.65          \n",
      "Training in progress @ step 2759 loss 0.619811 accuracy 0.78          \n",
      "Testing in progress @ step 2759 loss 0.942562 accuracy 0.62          \n",
      "Training in progress @ step 2779 loss 0.56467 accuracy 0.72          \n",
      "Testing in progress @ step 2779 loss 0.799797 accuracy 0.67          \n",
      "Training in progress @ step 2799 loss 0.636438 accuracy 0.7          \n",
      "Testing in progress @ step 2799 loss 0.612459 accuracy 0.74          \n",
      "saved @ weights/toynet-2799\n",
      "Training in progress @ step 2819 loss 0.842573 accuracy 0.58          \n",
      "Testing in progress @ step 2819 loss 0.885678 accuracy 0.63          \n",
      "Training in progress @ step 2839 loss 0.780674 accuracy 0.72          \n",
      "Testing in progress @ step 2839 loss 0.933522 accuracy 0.57          \n",
      "Training in progress @ step 2859 loss 0.65291 accuracy 0.8          \n",
      "Testing in progress @ step 2859 loss 0.799709 accuracy 0.72          \n",
      "Training in progress @ step 2879 loss 0.5746 accuracy 0.7          \n",
      "Testing in progress @ step 2879 loss 0.873283 accuracy 0.57          \n",
      "Training in progress @ step 2899 loss 0.937572 accuracy 0.56          \n",
      "Testing in progress @ step 2899 loss 1.17191 accuracy 0.53          \n",
      "saved @ weights/toynet-2899\n",
      "Training in progress @ step 2919 loss 0.708077 accuracy 0.74          \n",
      "Testing in progress @ step 2919 loss 0.722628 accuracy 0.73          \n",
      "Training in progress @ step 2939 loss 0.852072 accuracy 0.66          \n",
      "Testing in progress @ step 2939 loss 0.968192 accuracy 0.61          \n",
      "Training in progress @ step 2959 loss 0.657073 accuracy 0.72          \n",
      "Testing in progress @ step 2959 loss 0.789876 accuracy 0.6          \n",
      "Training in progress @ step 2979 loss 0.618192 accuracy 0.72          \n",
      "Testing in progress @ step 2979 loss 0.641927 accuracy 0.69          \n",
      "Training in progress @ step 2999 loss 0.797103 accuracy 0.56          \n",
      "Testing in progress @ step 2999 loss 1.12638 accuracy 0.48          \n",
      "saved @ weights/toynet-2999\n",
      "Training in progress @ step 3019 loss 0.804841 accuracy 0.62          \n",
      "Testing in progress @ step 3019 loss 0.846917 accuracy 0.62          \n",
      "Training in progress @ step 3039 loss 0.70976 accuracy 0.66          \n",
      "Testing in progress @ step 3039 loss 0.70021 accuracy 0.67          \n",
      "Training in progress @ step 3059 loss 0.689894 accuracy 0.78          \n",
      "Testing in progress @ step 3059 loss 0.98292 accuracy 0.57          \n",
      "Training in progress @ step 3079 loss 0.611111 accuracy 0.74          \n",
      "Testing in progress @ step 3079 loss 0.699165 accuracy 0.69          \n",
      "Training in progress @ step 3099 loss 0.744842 accuracy 0.64          \n",
      "Testing in progress @ step 3099 loss 1.35409 accuracy 0.51          \n",
      "saved @ weights/toynet-3099\n",
      "Training in progress @ step 3119 loss 0.807095 accuracy 0.6          \n",
      "Testing in progress @ step 3119 loss 0.802344 accuracy 0.64          \n",
      "Training in progress @ step 3139 loss 0.78203 accuracy 0.76          \n",
      "Testing in progress @ step 3139 loss 1.00904 accuracy 0.66          \n",
      "Training in progress @ step 3159 loss 0.65471 accuracy 0.76          \n",
      "Testing in progress @ step 3159 loss 0.841729 accuracy 0.64          \n",
      "Training in progress @ step 3179 loss 0.737708 accuracy 0.74          \n",
      "Testing in progress @ step 3179 loss 1.0513 accuracy 0.58          \n",
      "Training in progress @ step 3199 loss 0.6253 accuracy 0.72          \n",
      "Testing in progress @ step 3199 loss 0.61198 accuracy 0.68          \n",
      "saved @ weights/toynet-3199\n",
      "Training in progress @ step 3219 loss 0.917403 accuracy 0.6          \n",
      "Testing in progress @ step 3219 loss 0.893183 accuracy 0.68          \n",
      "Training in progress @ step 3239 loss 0.754437 accuracy 0.7          \n",
      "Testing in progress @ step 3239 loss 0.665836 accuracy 0.73          \n",
      "Training in progress @ step 3259 loss 0.653049 accuracy 0.72          \n",
      "Testing in progress @ step 3259 loss 0.745074 accuracy 0.59          \n",
      "Training in progress @ step 3279 loss 0.514316 accuracy 0.8          \n",
      "Testing in progress @ step 3279 loss 0.781733 accuracy 0.6          \n",
      "Training in progress @ step 3299 loss 1.38533 accuracy 0.46          \n",
      "Testing in progress @ step 3299 loss 1.20318 accuracy 0.62          \n",
      "saved @ weights/toynet-3299\n",
      "Training in progress @ step 3319 loss 0.761765 accuracy 0.58          \n",
      "Testing in progress @ step 3319 loss 0.69822 accuracy 0.67          \n",
      "Training in progress @ step 3339 loss 0.703768 accuracy 0.74          \n",
      "Testing in progress @ step 3339 loss 0.850714 accuracy 0.69          \n",
      "Training in progress @ step 3359 loss 0.565664 accuracy 0.8          \n",
      "Testing in progress @ step 3359 loss 0.93168 accuracy 0.56          \n",
      "Training in progress @ step 3379 loss 0.678501 accuracy 0.72          \n",
      "Testing in progress @ step 3379 loss 0.747349 accuracy 0.65          \n",
      "Training in progress @ step 3399 loss 0.615949 accuracy 0.74          \n",
      "Testing in progress @ step 3399 loss 0.750857 accuracy 0.62          \n",
      "saved @ weights/toynet-3399\n",
      "Training in progress @ step 3419 loss 0.688894 accuracy 0.66          \n",
      "Testing in progress @ step 3419 loss 0.697678 accuracy 0.67          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress @ step 3439 loss 0.728277 accuracy 0.76          \n",
      "Testing in progress @ step 3439 loss 0.864968 accuracy 0.7          \n",
      "Training in progress @ step 3459 loss 0.604869 accuracy 0.78          \n",
      "Testing in progress @ step 3459 loss 0.808686 accuracy 0.6          \n",
      "Training in progress @ step 3479 loss 0.539525 accuracy 0.78          \n",
      "Testing in progress @ step 3479 loss 0.881202 accuracy 0.67          \n",
      "Training in progress @ step 3499 loss 0.909235 accuracy 0.62          \n",
      "Testing in progress @ step 3499 loss 1.40428 accuracy 0.5          \n",
      "saved @ weights/toynet-3499\n",
      "Training in progress @ step 3519 loss 0.836295 accuracy 0.64          \n",
      "Testing in progress @ step 3519 loss 0.982234 accuracy 0.61          \n",
      "Training in progress @ step 3539 loss 0.696153 accuracy 0.76          \n",
      "Testing in progress @ step 3539 loss 1.13858 accuracy 0.65          \n",
      "Training in progress @ step 3559 loss 0.575298 accuracy 0.8          \n",
      "Testing in progress @ step 3559 loss 0.80772 accuracy 0.61          \n",
      "Training in progress @ step 3579 loss 0.604791 accuracy 0.7          \n",
      "Testing in progress @ step 3579 loss 0.878259 accuracy 0.58          \n",
      "Training in progress @ step 3599 loss 0.744733 accuracy 0.66          \n",
      "Testing in progress @ step 3599 loss 0.914084 accuracy 0.63          \n",
      "saved @ weights/toynet-3599\n",
      "Training in progress @ step 3619 loss 0.703805 accuracy 0.66          \n",
      "Testing in progress @ step 3619 loss 1.04688 accuracy 0.61          \n",
      "Training in progress @ step 3639 loss 0.680873 accuracy 0.74          \n",
      "Testing in progress @ step 3639 loss 1.29944 accuracy 0.55          \n",
      "Training in progress @ step 3659 loss 0.565129 accuracy 0.76          \n",
      "Testing in progress @ step 3659 loss 0.713539 accuracy 0.58          \n",
      "Training in progress @ step 3679 loss 0.496392 accuracy 0.78          \n",
      "Testing in progress @ step 3679 loss 0.870785 accuracy 0.68          \n",
      "Training in progress @ step 3699 loss 1.4254 accuracy 0.48          \n",
      "Testing in progress @ step 3699 loss 0.635963 accuracy 0.72          \n",
      "saved @ weights/toynet-3699\n",
      "Training in progress @ step 3719 loss 0.66809 accuracy 0.66          \n",
      "Testing in progress @ step 3719 loss 0.774028 accuracy 0.7          \n",
      "Training in progress @ step 3739 loss 0.801069 accuracy 0.64          \n",
      "Testing in progress @ step 3739 loss 0.946881 accuracy 0.67          \n",
      "Training in progress @ step 3759 loss 0.544251 accuracy 0.8          \n",
      "Testing in progress @ step 3759 loss 0.989096 accuracy 0.67          \n",
      "Training in progress @ step 3779 loss 0.555648 accuracy 0.76          \n",
      "Testing in progress @ step 3779 loss 0.87806 accuracy 0.69          \n",
      "Training in progress @ step 3799 loss 1.22594 accuracy 0.46          \n",
      "Testing in progress @ step 3799 loss 1.06543 accuracy 0.63          \n",
      "saved @ weights/toynet-3799\n",
      "Training in progress @ step 3819 loss 0.666915 accuracy 0.72          \n",
      "Testing in progress @ step 3819 loss 0.852657 accuracy 0.69          \n",
      "Training in progress @ step 3839 loss 0.875728 accuracy 0.64          \n",
      "Testing in progress @ step 3839 loss 0.869272 accuracy 0.59          \n",
      "Training in progress @ step 3859 loss 0.559065 accuracy 0.8          \n",
      "Testing in progress @ step 3859 loss 0.71733 accuracy 0.74          \n",
      "Training in progress @ step 3879 loss 0.50177 accuracy 0.78          \n",
      "Testing in progress @ step 3879 loss 0.84525 accuracy 0.64          \n",
      "Training in progress @ step 3899 loss 0.695553 accuracy 0.72          \n",
      "Testing in progress @ step 3899 loss 1.17516 accuracy 0.53          \n",
      "saved @ weights/toynet-3899\n",
      "Training in progress @ step 3919 loss 1.05479 accuracy 0.54          \n",
      "Testing in progress @ step 3919 loss 0.687272 accuracy 0.72          \n",
      "Training in progress @ step 3939 loss 0.722689 accuracy 0.7          \n",
      "Testing in progress @ step 3939 loss 1.05581 accuracy 0.61          \n",
      "Training in progress @ step 3959 loss 0.619665 accuracy 0.78          \n",
      "Testing in progress @ step 3959 loss 0.874952 accuracy 0.63          \n",
      "Training in progress @ step 3979 loss 0.605507 accuracy 0.8          \n",
      "Testing in progress @ step 3979 loss 0.757266 accuracy 0.64          \n",
      "Training in progress @ step 3999 loss 0.543955 accuracy 0.76          \n",
      "Testing in progress @ step 3999 loss 0.699701 accuracy 0.69          \n",
      "saved @ weights/toynet-3999\n",
      "\n",
      "Run `tensorboard --logdir=log` in terminal to see the results.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 4: Run training loop\n",
    "#\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    train_data  = train_io.fetch_data('train_image').data()\n",
    "    train_label = train_io.fetch_data('train_label').data()\n",
    "\n",
    "    feed_dict = { data_tensor  : train_data,\n",
    "                  label_tensor : train_label }\n",
    "\n",
    "    loss, acc, _ = sess.run([cross_entropy, accuracy, train_step], feed_dict=feed_dict)\n",
    "\n",
    "    if (i+1)%SAVE_SUMMARY == 0:\n",
    "        # Save train log\n",
    "        sys.stdout.write('Training in progress @ step %d loss %g accuracy %g          \\n' % (i,loss,acc))\n",
    "        sys.stdout.flush()\n",
    "        s = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        writer_train.add_summary(s,i)\n",
    "    \n",
    "        # Calculate & save test log\n",
    "        test_data  = test_io.fetch_data('test_image').data()\n",
    "        test_label = test_io.fetch_data('test_label').data()\n",
    "        feed_dict  = { data_tensor  : test_data,\n",
    "                       label_tensor : test_label }\n",
    "        loss, acc = sess.run([cross_entropy, accuracy], feed_dict=feed_dict)\n",
    "        sys.stdout.write('Testing in progress @ step %d loss %g accuracy %g          \\n' % (i,loss,acc))\n",
    "        sys.stdout.flush()\n",
    "        s = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        writer_test.add_summary(s,i)\n",
    "        \n",
    "        test_io.next()\n",
    "\n",
    "    train_io.next()\n",
    "\n",
    "    if (i+1)%SAVE_WEIGHTS == 0:\n",
    "        ssf_path = saver.save(sess,'weights/toynet',global_step=i)\n",
    "        print 'saved @',ssf_path\n",
    "\n",
    "# inform log directory\n",
    "print\n",
    "print 'Run `tensorboard --logdir=%s` in terminal to see the results.' % LOGDIR\n",
    "train_io.reset()\n",
    "test_io.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking log on the tensorboard\n",
    "As the last line above says you can visualize your log using tensorboard. This command\n",
    "```\n",
    "tensorboard --logdir=log\n",
    "```\n",
    "on the terminal instantiates the tensorboard server and tells the localhost address to access through your web-browser. You can certainly [ssh-tunnel](https://www.ssh.com/ssh/tunneling/) to access the _localhost_ of your remote machine to check it on your local machine's web-browser as well. For the above training, here's the screenshot of the loss and accuracy curve for train and test samples where the *blue* line represents metric measured on the training set and *orange* line is for the same on the test sample.\n",
    "\n",
    "![loss](imgs/tutorial05-training-classification-loss.png)\n",
    "\n",
    "![accuracy](imgs/tutorial05-training-classification-accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covered training convolutional neural networks to perform image classification of 5 LArTPC particles using a practice files. We encourage you to design your own network and train on our [public dataset](http://deeplearnphysics.org/DataChallenge)! We provide 50,000 entries of 5 particle images (10,000 per particle) for training and separate 40,000 for testing your network. When you are confident, try our *data challenge*, yet another set of 40,000 events without _answers_ (i.e. no `particle` information). Share your awesome result in the CSV format to [us](contact@deeplearnphysics.org) with your network architecture made available on a github repository. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
